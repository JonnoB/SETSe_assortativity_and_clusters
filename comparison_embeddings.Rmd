---
title: "Untitled"
author: "Jonathan Bourne"
date: "18/05/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

This markdown is to convert the basic set of peels quintet graphs to the graphML format, so that they can be imported into python and used witht the GEM, library.

This markdown file should be run after all chunks in `Introduction_to_sets2.Rmd`  down to `peel strain` has been run

#Create graphml

```{r}
graphml_path <- file.path(PLwd, "peels_graphml")

.x <- 200

1:500 %>% walk(~{
graph_id <- .x


g <-multi_quintet[[graph_id]] 
graph_type <- graph_attr(g, "type")

file_path <- file.path(graphml_path, paste0("graph_id_", graph_id, "_type_", graph_type, ".graphml"))

g %>% 
  delete_vertex_attr(., "sub_class") %>%
  delete_vertex_attr(., "node") %>%
  delete_edge_attr(., "type") %>%
  delete_graph_attr(., "type")  %>%
  set.vertex.attribute("class", 
                       value = as.numeric(as.factor(get.vertex.attribute(., "class")))-1)%>%
  write_graph(., file_path, format = "graphml")

}
  )


g %>% 
  delete_vertex_attr(., "sub_class") %>%
  delete_vertex_attr(., "node") %>%
  delete_edge_attr(., "type") %>%
  delete_graph_attr(., "type")  %>%
  set.vertex.attribute("class", 
                       value = as.numeric(as.factor(get.vertex.attribute(., "class")))) %>%
  as_data_frame(., what = "vertices")

```


##Weighted graphml

This chunk creates a weighted network where the edge weights/distances are the strain of the SETSe embeddings. 
This effectively acts as a double embeddings where first the network is embedded using SETSe and second the network is embedded using the methods in GEM
```{r}

1:500 %>% walk(~{
  #get the ith network
g <- multi_quintet[[.x]]
#extract the type which will be used in the filename of the graphml file
graph_type <- graph_attr(g, "type")
#get the edge list of the network
g_edge <- as_data_frame(g)
#create the name of the graphml file
file_path <- file.path(file.path(PLwd, "peels_weighted_graphml"), 
                       paste0("graph_id_", .x, "_type_", graph_type, ".graphml"))
#load the SETSe embedded data of the same network that has been loaded
embeddings_data <- read_rds(list.files(file.path(PLwd, "peel_strain_files"), 
                                       full.names= T, 
                                       patter = paste("ref", .x, "k_0", sep = "_")) )
#extract the edge embeddings
g_edge <- embeddings_data$edge_embeddings %>%
  separate(col = "edge_name", into = c("from", "to"), sep = "_", remove = FALSE, convert = T, ) %>%
  select(from, to, tension) %>%
  left_join(g_edge, ., by = c("from", "to")) %>%
  select(from, to, weight = tension)

#re-assemble to graph with edge weights as graph embeddings
graph_from_data_frame(g_edge, directed = FALSE) %>%
  write_graph(., file_path, format = "graphml")

print(paste("network", .x, "graph type", graph_type, "completed"))

}
)


```

#Directed

I was worried that GEM was not embedding properly, due to some wording in the documentation. To check I created symmetrical directed graphs. THe result was the same. so now worries

```{r}
# 1:500 %>% walk(~{
#   #get the ith network
# g <- multi_quintet[[.x]]
# #extract the type which will be used in the filename of the graphml file
# graph_type <- graph_attr(g, "type")
# #get the edge list of the network
# g_edge <- as_data_frame(g)
# #create the name of the graphml file
# file_path <- file.path(file.path(PLwd, "peels_graphml"), 
#                        paste0("graph_id_", .x, "_type_", graph_type, ".graphml"))
# 
# #extract the edge embeddings
# g_edge <- g_edge %>%
#   rename(c = from, from = to) %>%
#   rename(to = c) %>%
#   bind_rows(g_edge) %>%
#   select(-type)
# 
# #re-assemble to graph with edge weights as graph embeddings
# graph_from_data_frame(g_edge, directed = TRUE) %>%
#   write_graph(., file_path, format = "graphml")
# 
# print(paste("network", .x, "graph type", graph_type, "completed"))
# 
# }
# )
```

#load back in the embeddings

##gem embeddings

These are the embeddings created by the GEM library
```{r}



peels_metrics <- metric_set(accuracy, precision, recall, f_meas)


embedded_files <- list.files(file.path(PLwd, "peel_benchmark_embeddings2"), full.names = T)
#calculate the embedding sub-class classification
include <-!grepl(embedded_files, pattern = "SDNE")
GEM_embeds <- embedded_files[include] %>%
  map_df(~{
    
    print(.x)
    embedded_path <- .x#embedded_files[50]
    
    #split the file name to get the graph information
    graph_data <- str_split(basename(embedded_path), pattern = "_", simplify = T )
    
    #read the csv in from the folder
    csv_df <- read.csv(embedded_path, header = FALSE) #col_names = FALSE)
    
    #add the embedding values to the matching graph
    g_temp <- multi_quintet[[as.integer(graph_data[6])]]
    for(i in 1:ncol(csv_df)){
    #add in each dimension in the dataset
    g_temp <-  g_temp %>%
      set_vertex_attr(., paste0("dimension_", i), value =  csv_df %>% pull(i))
      
      
    }

    #create dataframe to perform linear separation analysis on
    test_df <- as_data_frame(g_temp, what = "vertices") %>%
      mutate(class = factor(class),
             sub_class = factor(sub_class))
    
    #a couple of the methods have twice as many dimensions but half of them are doubles.
    #This means the matrices are not full rank
    #ensureing only the first half of the variables are taken means that the matrices become full rank again
    number_of_columns <-3+as.integer(graph_data[3])
    
    class_formula <- as.formula(paste("class", 
                                      paste(names(test_df)[4:number_of_columns], collapse=" + "), sep=" ~ "))
    sub_class_formula <- as.formula(paste("sub_class", 
                                          paste(names(test_df)[4:number_of_columns], collapse=" + "), sep=" ~ "))
    
    #class_mod <- svm(class ~  dimension_2, test_df, kernel = "linear")
    class_mod <- vglm( class_formula , family=multinomial, data = test_df)
    
    #sub_mod <- svm(sub_class ~  dimension_2, test_df, kernel = "linear")
    sub_mod <- vglm(sub_class_formula, family=multinomial, data = test_df)
    
    class_preds_vect <- predict(class_mod, decision.values = TRUE, type = "response") %>% { colnames(.)[apply(., 1, which.max)]}
    sub_preds_vect <- predict(sub_mod, decision.values = TRUE, type = "response") %>% { colnames(.)[apply(., 1, which.max)]}
    
        test_df <- test_df %>%
      mutate(class_preds =  factor(class_preds_vect, levels = c("A", "B")),
             sub_preds  = factor(sub_preds_vect, levels = c("A_1", "A_2", "B_1", "B_2")))
        
    # test_df <- test_df %>%
    #   mutate(class_preds = predict(class_mod, decision.values = TRUE),
    #          sub_preds  = predict(sub_mod, decision.values = TRUE))
    
    bind_rows(peels_metrics(test_df, truth = class, estimate = class_preds) %>%
                mutate(model_type = "class"),
              peels_metrics(test_df, truth = sub_class, estimate = sub_preds)%>%
                mutate(model_type = "sub_class")
    ) %>%
      mutate(embeddings_method = graph_data[1],
             embeddings_dimensions = graph_data[3],
             graph_id = as.integer(graph_data[6]),
             type = str_remove(graph_data[8], pattern = ".csv"))
    
  })


GEM_embeds %>%
  filter(.metric =="accuracy") %>%
  ggplot(aes(x = embeddings_method, y = .estimate, fill = embeddings_method)) + geom_boxplot()+
  facet_wrap(type~model_type)
 
#plot example graph
test_df %>%
ggplot(., aes(x = dimension_1, y= dimension_2, colour = sub_class) ) + geom_point()


#Calculate the average x y points for the embeddings
GEM_embeds_agg <- embedded_files %>%
  map_df(~{
    
    print(.x)
    embedded_path <- .x#embedded_files[50]
    
    #split the file name to get the graph information
    graph_data <- str_split(basename(embedded_path), pattern = "_", simplify = T )
    
    #read the csv in from the folder
    csv_df <- read.csv(embedded_path, header = FALSE) #col_names = FALSE)
    
    #add the embedding values to the matching graph
    g_temp <- multi_quintet[[as.integer(graph_data[6])]] %>%
      set_vertex_attr(., "dimension_1", value =  csv_df %>% pull(1)) %>%
      set_vertex_attr(., "dimension_2", value =  csv_df %>% pull(2))
    
    #create dataframe to perform linear separation analysis on
    test_df <- as_data_frame(g_temp, what = "vertices") %>%
      mutate(class = factor(class),
             sub_class = factor(sub_class)) %>%
      mutate(embeddings_method = graph_data[1],
             embeddings_dimensions = graph_data[3],
             graph_id = as.integer(graph_data[6]),
             type = str_remove(graph_data[8], pattern = ".csv"))
   
    
  }) %>%
  group_by(embeddings_method, graph_id, type, embeddings_dimensions) %>%
  summarise(dimension_1 = mean(dimension_1),
            dimension_2 = mean(dimension_2))

test_df %>% group_by(embeddings_method, graph_id, type, embeddings_dimensions) %>%
  summarise(across(where(is.numeric)),mean)

GEM_embeds_agg %>%
  ggplot(aes(x = dimension_1, y = dimension_2, colour = type)) + 
  geom_point() +
  facet_wrap(~embeddings_method)


```

#load setse values
```{r}

node_data2 <- readRDS(file.path(PLwd, "node_data2.rds"))

#why are there apparently double rows? what is happening with the detected communities dataframe
SETSe_embeds <- 1:500 %>%
  map_df(~{
    
    test_df <- node_data2 %>%
      filter(graph_id == .x) %>%
      mutate(class = factor(class),
             sub_class = factor(sub_class)) %>%
      rename(dimension_1 = elevation, 
             dimension_2 = tension_mean)
    
    #class_mod <- svm(class ~  dimension_2, test_df, kernel = "linear")
    class_mod <- vglm(class ~ dimension_1 + dimension_2, family=multinomial, data = test_df)
    
    #sub_mod <- svm(sub_class ~  dimension_2, test_df, kernel = "linear")
    sub_mod <- vglm(sub_class ~ dimension_1 + dimension_2, family=multinomial, data = test_df)
    
    class_preds_vect <- predict(class_mod, decision.values = TRUE, type = "response") %>% { colnames(.)[apply(., 1, which.max)]}
    sub_preds_vect <- predict(sub_mod, decision.values = TRUE, type = "response") %>% { colnames(.)[apply(., 1, which.max)]}
    
        test_df <- test_df %>%
      mutate(class_preds =  factor(class_preds_vect, levels = c("A", "B")),
             sub_preds  = factor(sub_preds_vect, levels = c("A_1", "A_2", "B_1", "B_2")))
        
    # test_df <- test_df %>%
    #   mutate(class_preds = predict(class_mod, decision.values = TRUE),
    #          sub_preds  = predict(sub_mod, decision.values = TRUE))
    
    bind_rows(peels_metrics(test_df, truth = class, estimate = class_preds) %>%
                mutate(model_type = "class"),
              peels_metrics(test_df, truth = sub_class, estimate = sub_preds)%>%
                mutate(model_type = "sub_class")
    ) %>%
      mutate(embeddings_method = "SETSe",
             embeddings_dimensions = "2",
             graph_id = as.integer(.x),
             type = unique(test_df%>% pull(graph_class)))
    
    
  })


node_data_agg <-node_data2 %>%
  rename(type = graph_class) %>%
  group_by(graph_id, type) %>%
  summarise(dimension_1 = mean(tension_mean), 
            dimension_2 = mean(abs(elevation))) %>%
  ungroup %>%
      mutate(embeddings_method = "SETSe",
             embeddings_dimensions = "2",
             graph_id = as.integer(graph_id))

GEM_embeds_agg %>%
  group_by(embeddings_method) %>%
  summarise(counts = n())
```

#node2vec

```{r}



node2vec_embeds <- list.files(file.path(PLwd, "node2vec_embeddings"), full.names = TRUE)

node_perf <- node2vec_embeds %>%
  map_df(~{
    
      print(.x)
    embedded_path <- .x#embedded_files[50]
    
    #split the file name to get the graph information
    graph_data <- str_split(basename(embedded_path), pattern = "_", simplify = T )
    
    #read the csv in from the folder
    csv_df <- read.table(embedded_path, header = FALSE, sep = " ", skip = 1) %>%
      mutate(V1 = str_remove(V1, "n") %>% as.integer() %>%{as.character(.+1)})
    
    #add the embedding values to the matching graph
    g_temp <- multi_quintet[[as.integer(graph_data[7])]] #%>%
     # set_vertex_attr(., "dimension_1", value =  csv_df %>% pull(1)) %>%
     # set_vertex_attr(., "dimension_2", value =  csv_df %>% pull(2))
    
    #create dataframe to perform linear separation analysis on
    test_df <- as_data_frame(g_temp, what = "vertices") %>%
      left_join(csv_df, by = c("node"="V1")) %>%
      mutate(class = factor(class),
             sub_class = factor(sub_class))
    
  dimensions_names <-   paste0("dimension_", 1:length(    names(test_df)[-c(1:3)]))
    
    names(test_df)[-c(1:3)] <-   dimensions_names
    
    
    class_formula <- as.formula(paste("class", 
                                      paste(names(test_df)[4:ncol(test_df)], collapse=" + "), sep=" ~ "))
    sub_class_formula <- as.formula(paste("sub_class", 
                                          paste(names(test_df)[4:ncol(test_df)], collapse=" + "), sep=" ~ "))
    
    class_mod <- vglm( class_formula , family=multinomial, data = test_df)
    
    sub_mod <- vglm(sub_class_formula, family=multinomial, data = test_df)
    
    
    class_preds_vect <- predict(class_mod, decision.values = TRUE, type = "response") %>% { colnames(.)[apply(., 1, which.max)]}
    sub_preds_vect <- predict(sub_mod, decision.values = TRUE, type = "response") %>% { colnames(.)[apply(., 1, which.max)]}
    
        test_df <- test_df %>%
      mutate(class_preds =  factor(class_preds_vect, levels = c("A", "B")),
             sub_preds  = factor(sub_preds_vect, levels = c("A_1", "A_2", "B_1", "B_2")))
        
    # test_df <- test_df %>%
    #   mutate(class_preds = predict(class_mod, decision.values = TRUE),
    #          sub_preds  = predict(sub_mod, decision.values = TRUE))
    
    bind_rows(peels_metrics(test_df, truth = class, estimate = class_preds) %>%
                mutate(model_type = "class"),
              peels_metrics(test_df, truth = sub_class, estimate = sub_preds)%>%
                mutate(model_type = "sub_class")
              ) %>%
      mutate(embeddings_method = graph_data[1],
             embeddings_dimensions = graph_data[4],
             graph_id = as.integer(graph_data[7]),
             type = str_remove(graph_data[9], pattern = ".csv"))
    
    
  })




n2v_embeds_agg <-  node2vec_embeds %>%
  map_df(~{
    
    print(.x)
    embedded_path <- .x#embedded_files[50]
    
    #split the file name to get the graph information
    graph_data <- str_split(basename(embedded_path), pattern = "_", simplify = T )
    
    #read the csv in from the folder
    csv_df <- read.table(embedded_path, header = FALSE, sep = " ", skip = 1) %>%
      mutate(V1 = str_remove(V1, "n") %>% as.integer() %>%{as.character(.+1)})
    
    #add the embedding values to the matching graph
    g_temp <- multi_quintet[[as.integer(graph_data[7])]] 
    
    #create dataframe to perform linear separation analysis on
    test_df <- as_data_frame(g_temp, what = "vertices") %>%
      left_join(csv_df, by = c("node"="V1")) %>%
    rename(dimension_1 = V2, dimension_2 = V3) %>%
      mutate(class = factor(class),
             sub_class = factor(sub_class))%>%
      mutate(embeddings_method = graph_data[1],
             embeddings_dimensions = graph_data[4],
             graph_id = as.integer(graph_data[7]),
             type = str_remove(graph_data[9], pattern = ".csv"))
   
    
  }) %>%
  group_by(embeddings_method, graph_id, type, embeddings_dimensions) %>%
  summarise(dimension_1 = mean(dimension_1),
            dimension_2 = mean(dimension_2))


```

#node2vec stellar

```{r}

n2v_stellar_embedded_files <- list.files("/home/jonno/setse_1_data/peel_benchmark_stellargraph_node2vec2", full.names = T)


#This loop has code to remove zero variance columns as these cause a rank deficiency in the classification algo
#The two dimensions can also be perfectly corellated, this is also corrected
n2v_stellar_embeds <- n2v_stellar_embedded_files  %>%
  map_df(~{
    
    print(.x)
    embedded_path <- .x#embedded_files[50]
    
    #split the file name to get the graph information
    graph_data <- str_split(basename(embedded_path), pattern = "_", simplify = T )
    
    #read the csv in from the folder
    csv_df <- read_delim(embedded_path, 
                         delim = " ",
                         col_names = FALSE,
                         skip = 1
                         ) 
    
    names(csv_df) <- paste0("V", 1:ncol(csv_df))
    zero_var_cols <- nearZeroVar(csv_df ) #identify zero var columns
    csv_df <- csv_df %>% select(-all_of(zero_var_cols)) #remove zero var columns
    
    #in the case that there is more than 1 data column after the 0 variance colunmns have been removed then check for perfect corellation
    if(ncol(csv_df)>2){
      print("checking for correlation")
      #froms stack overflow 
      #https://stackoverflow.com/questions/18275639/remove-highly-correlated-variables
      df2 = cor(csv_df %>%select(-V1))
      hc = findCorrelation(df2, cutoff=0.99) # putt any value as a "cutoff" 
      hc = sort(hc)+1 #add one as there is the name column
      csv_df = csv_df%>% select(-all_of(hc)) #[,-c(hc)]
    }
    
  

    #add the embedding values to the matching graph
    g_temp <- multi_quintet[[as.integer(graph_data[6])]]
    
    if(ncol(csv_df)==1){
      
    test_df <- as_data_frame(g_temp, what = "vertices") %>%
      mutate(class = factor(class),
             sub_class = factor(sub_class)) %>%
      mutate(class_preds = ifelse(class =="A", "B", "A"),
             sub_preds = ifelse(sub_class =="A_1", "B_1", "A_1"),
             class_preds =  factor(class_preds, levels = c("A", "B")),
             sub_preds  = factor(sub_preds, levels = c("A_1", "A_2", "B_1", "B_2"))
             )
      
    } else {
    
    # for(i in 2:ncol(csv_df)){ #The first column from the stellargraph is the node id
    # #add in each dimension in the dataset
    # g_temp <-  g_temp %>%
    #   set_vertex_attr(., paste0("dimension_", i), value =  csv_df %>% pull(i))
    #   
    #   
    # }

    number_of_variables_df <-ncol(csv_df)-1
    
    #create dataframe to perform linear separation analysis on
    # test_df <- as_data_frame(g_temp, what = "vertices") %>%
    #   mutate(class = factor(class),
    #          sub_class = factor(sub_class))
    
    test_df <- as_data_frame(g_temp, what = "vertices") %>%
      left_join(csv_df %>%
      mutate(V1 = str_remove(V1, "n") %>% as.numeric()+1,
             V1 = as.character(V1)), by = c("node"="V1")) %>%
      mutate(class = factor(class),
             sub_class = factor(sub_class))
    
    #a couple of the methods have twice as many dimensions but half of them are doubles.
    #This means the matrices are not full rank
    #ensureing only the first half of the variables are taken means that the matrices become full rank again
    number_of_columns <-3+ number_of_variables_df
    
    class_formula <- as.formula(paste("class", 
                                      paste(names(test_df)[4:number_of_columns], collapse=" + "), sep=" ~ "))
    sub_class_formula <- as.formula(paste("sub_class", 
                                          paste(names(test_df)[4:number_of_columns], collapse=" + "), sep=" ~ "))
    
    #class_mod <- svm(class ~  dimension_2, test_df, kernel = "linear")
    class_mod <- vglm( class_formula , family=multinomial, data = test_df)
    
    #sub_mod <- svm(sub_class ~  dimension_2, test_df, kernel = "linear")
    sub_mod <- vglm(sub_class_formula, family=multinomial, data = test_df)
    
    class_preds_vect <- predict(class_mod, decision.values = TRUE, type = "response") %>% 
      { colnames(.)[apply(., 1, which.max)]}
    sub_preds_vect <- predict(sub_mod, decision.values = TRUE, type = "response") %>% 
      { colnames(.)[apply(., 1, which.max)]}
    
    test_df <- test_df %>%
      mutate(class_preds =  factor(class_preds_vect, levels = c("A", "B")),
             sub_preds  = factor(sub_preds_vect, levels = c("A_1", "A_2", "B_1", "B_2")))
       
    } 
    # test_df <- test_df %>%
    #   mutate(class_preds = predict(class_mod, decision.values = TRUE),
    #          sub_preds  = predict(sub_mod, decision.values = TRUE))
    
    bind_rows(peels_metrics(test_df, truth = class, estimate = class_preds) %>%
                mutate(model_type = "class"),
              peels_metrics(test_df, truth = sub_class, estimate = sub_preds)%>%
                mutate(model_type = "sub_class")
    ) %>%
      mutate(embeddings_method = graph_data[1],
             embeddings_dimensions = graph_data[3],
             graph_id = as.integer(graph_data[6]),
             type = str_remove(graph_data[8], pattern = ".csv"))
    
  })


n2v_stellar_embeds_agg <-  n2v_stellar_embedded_files %>%
  map_df(~{
    
    print(.x)
    embedded_path <- .x#embedded_files[50]
    
    #split the file name to get the graph information
    graph_data <- str_split(basename(embedded_path), pattern = "_", simplify = T )
    
    #read the csv in from the folder
    csv_df <- read.table(embedded_path, header = FALSE, sep = " ", skip = 1) %>%
      mutate(V1 = str_remove(V1, "n") %>% as.integer() %>%{as.character(.+1)})
    
    #add the embedding values to the matching graph
    g_temp <- multi_quintet[[as.integer(graph_data[6])]] 
    
    #create dataframe to perform linear separation analysis on
    test_df <- as_data_frame(g_temp, what = "vertices") %>%
      left_join(csv_df, by = c("node"="V1")) %>%
    rename(dimension_1 = V2, dimension_2 = V3) %>%
      mutate(class = factor(class),
             sub_class = factor(sub_class))%>%
      mutate(embeddings_method = graph_data[1],
             embeddings_dimensions = graph_data[3],
             graph_id = as.integer(graph_data[6]),
             type = str_remove(graph_data[8], pattern = ".csv"))
   
    
  }) %>%
  group_by(embeddings_method, graph_id, type, embeddings_dimensions) %>%
  summarise(dimension_1 = mean(dimension_1),
            dimension_2 = mean(dimension_2))

bind_rows(n2v_embeds_agg, n2v_stellar_embeds_agg %>% rename(dimension_3 = dimension_1, dimension_1 = dimension_2) %>% rename(dimension_2 = dimension_3) %>% mutate(embeddings_method = "stellar")
            ) %>%
  ggplot(aes(x = dimension_1, y = dimension_2, colour = type)) + 
  facet_wrap(~embeddings_method) + 
  geom_point()


n2v_stellar_embeds_agg %>%
  ggplot(aes(x = dimension_2, y = dimension_1, colour = type)) + 
  geom_point() + theme_void() + theme(
  panel.background = element_rect(fill = "grey22",
                                colour = "darkgrey",
                                size = 0.5, linetype = "solid")
  ) +
  guides(fill=FALSE, 
                                       color=FALSE) 
  
  
  

bind_rows(
  node_perf,
  n2v_stellar_embeds %>% mutate(embeddings_method = "stellar")
) %>%
  filter(.metric =="accuracy") %>%
  mutate(type2 = paste0("Type ", type,": ", model_type, " detection") %>% str_replace(., "_", " ")) %>%
  ggplot(aes(x = embeddings_method, y = .estimate, fill = embeddings_method)) + geom_boxplot()+
  facet_wrap(~type2)


```


#DGI

THis is the cleaning for the DGI method using Stellargraph

```{r}
.x <- "/home/jonno/setse_1_data/peel_benchmark_stellargraph2/DGI_d_2_graph_id_12_type_A.csv"


DGI_embedded_files <- list.files("/home/jonno/setse_1_data/peel_benchmark_stellargraph2", full.names = T)


#This loop has code to remove zero variance columns as these cause a rank deficiency in the classification algo
#The two dimensions can also be perfectly corellated, this is also corrected
DGI_embeds <- DGI_embedded_files  %>%
  map_df(~{
    
    print(.x)
    embedded_path <- .x#embedded_files[50]
    
    #split the file name to get the graph information
    graph_data <- str_split(basename(embedded_path), pattern = "_", simplify = T )
    
    #read the csv in from the folder
    csv_df <- read.csv(embedded_path, header = FALSE, skip = 1) #col_names = FALSE)
    zero_var_cols <- nearZeroVar(csv_df ) #identify zero var columns
    csv_df <- csv_df %>% select(-all_of(zero_var_cols)) #remove zero var columns
    
    #in the case that there is more than 1 data column after the 0 variance colunmns have been removed then check for perfect corellation
    if(ncol(csv_df)>2){
      print("checking for correlation")
      #froms stack overflow 
      #https://stackoverflow.com/questions/18275639/remove-highly-correlated-variables
      df2 = cor(csv_df %>%select(-V1))
      hc = findCorrelation(df2, cutoff=0.99) # putt any value as a "cutoff" 
      hc = sort(hc)+1 #add one as there is the name column
      csv_df = csv_df%>% select(-all_of(hc)) #[,-c(hc)]
    }
    
  

    #add the embedding values to the matching graph
    g_temp <- multi_quintet[[as.integer(graph_data[6])]]
    
    if(ncol(csv_df)==1){
      
    test_df <- as_data_frame(g_temp, what = "vertices") %>%
      mutate(class = factor(class),
             sub_class = factor(sub_class)) %>%
      mutate(class_preds = ifelse(class =="A", "B", "A"),
             sub_preds = ifelse(sub_class =="A_1", "B_1", "A_1"),
             class_preds =  factor(class_preds, levels = c("A", "B")),
             sub_preds  = factor(sub_preds, levels = c("A_1", "A_2", "B_1", "B_2"))
             )
      
    } else {
    
    # for(i in 2:ncol(csv_df)){ #The first column from the stellargraph is the node id
    # #add in each dimension in the dataset
    # g_temp <-  g_temp %>%
    #   set_vertex_attr(., paste0("dimension_", i), value =  csv_df %>% pull(i))
    #   
    #   
    # }

    number_of_variables_df <-ncol(csv_df)-1
    
    #create dataframe to perform linear separation analysis on
    # test_df <- as_data_frame(g_temp, what = "vertices") %>%
    #   mutate(class = factor(class),
    #          sub_class = factor(sub_class))
    
    test_df <- as_data_frame(g_temp, what = "vertices") %>%
      left_join(csv_df %>%
      mutate(V1 = str_remove(V1, "n") %>% as.numeric()+1,
             V1 = as.character(V1)), by = c("node"="V1")) %>%
      mutate(class = factor(class),
             sub_class = factor(sub_class))
    
    #a couple of the methods have twice as many dimensions but half of them are doubles.
    #This means the matrices are not full rank
    #ensureing only the first half of the variables are taken means that the matrices become full rank again
    number_of_columns <-3+ number_of_variables_df
    
    class_formula <- as.formula(paste("class", 
                                      paste(names(test_df)[4:number_of_columns], collapse=" + "), sep=" ~ "))
    sub_class_formula <- as.formula(paste("sub_class", 
                                          paste(names(test_df)[4:number_of_columns], collapse=" + "), sep=" ~ "))
    
    #class_mod <- svm(class ~  dimension_2, test_df, kernel = "linear")
    class_mod <- vglm( class_formula , family=multinomial, data = test_df)
    
    #sub_mod <- svm(sub_class ~  dimension_2, test_df, kernel = "linear")
    sub_mod <- vglm(sub_class_formula, family=multinomial, data = test_df)
    
    class_preds_vect <- predict(class_mod, decision.values = TRUE, type = "response") %>% 
      { colnames(.)[apply(., 1, which.max)]}
    sub_preds_vect <- predict(sub_mod, decision.values = TRUE, type = "response") %>% 
      { colnames(.)[apply(., 1, which.max)]}
    
    test_df <- test_df %>%
      mutate(class_preds =  factor(class_preds_vect, levels = c("A", "B")),
             sub_preds  = factor(sub_preds_vect, levels = c("A_1", "A_2", "B_1", "B_2")))
       
    } 
    # test_df <- test_df %>%
    #   mutate(class_preds = predict(class_mod, decision.values = TRUE),
    #          sub_preds  = predict(sub_mod, decision.values = TRUE))
    
    bind_rows(peels_metrics(test_df, truth = class, estimate = class_preds) %>%
                mutate(model_type = "class"),
              peels_metrics(test_df, truth = sub_class, estimate = sub_preds)%>%
                mutate(model_type = "sub_class")
    ) %>%
      mutate(embeddings_method = graph_data[1],
             embeddings_dimensions = graph_data[3],
             graph_id = as.integer(graph_data[6]),
             type = str_remove(graph_data[8], pattern = ".csv"))
    
  })

#Running the prediction on the below file then plotting the embedding shows why type E is so high for subclass and yet low for class.
#.x<- "/home/jonno/setse_1_data/peel_benchmark_stellargraph2/DGI_d_2_graph_id_496_type_E.csv"
#test_df %>% ggplot(aes(x = V2, colour = sub_class)) + geom_density()
#The

# 25% of the models did not converge
table(DGI_embeds$.metric, DGI_embeds$.estimate==0)
table(DGI_embeds$type, DGI_embeds$.estimate==0)
DGI_embeds %>%
  filter(.estimate !=0) %>%
  filter(.metric =="accuracy") %>%
  ggplot(aes(x = embeddings_method, y = .estimate, fill = embeddings_method)) + geom_boxplot()+
  facet_wrap(type~model_type)


#Calculate the average x y points for the embeddings
DGI_embeds_agg <- DGI_embedded_files  %>%
  map_df(~{
    
    print(.x)
    embedded_path <- .x#embedded_files[50]
    
    #split the file name to get the graph information
    graph_data <- str_split(basename(embedded_path), pattern = "_", simplify = T )
    
    #read the csv in from the folder
    csv_df <- read.csv(embedded_path, header = FALSE, skip = 1) #col_names = FALSE)
    
    #add the embedding values to the matching graph
    g_temp <- multi_quintet[[as.integer(graph_data[6])]] %>%
      set_vertex_attr(., "dimension_1", value =  csv_df %>% pull(2)) %>%
      set_vertex_attr(., "dimension_2", value =  csv_df %>% pull(3))
    
    #create dataframe to perform linear separation analysis on
    test_df <- as_data_frame(g_temp, what = "vertices") %>%
      mutate(class = factor(class),
             sub_class = factor(sub_class)) %>%
      mutate(embeddings_method = graph_data[1],
             embeddings_dimensions = graph_data[3],
             graph_id = as.integer(graph_data[6]),
             type = str_remove(graph_data[8], pattern = ".csv"))
   
    
  }) %>%
  group_by(embeddings_method, graph_id, type, embeddings_dimensions) %>%
  summarise(dimension_1 = mean(dimension_1),
            dimension_2 = mean(dimension_2))

test_df %>% group_by(embeddings_method, graph_id, type, embeddings_dimensions) %>%
  summarise(across(where(is.numeric)),mean)

DGI_embeds_agg  %>%
  ggplot(aes(x = dimension_1, y = dimension_2, colour = type)) + 
  geom_point() +
  facet_wrap(~embeddings_method)

```


#compare methods

##all network embeds
```{r}
bind_rows(GEM_embeds_agg, n2v_embeds_agg, node_data_agg, DGI_embeds_agg) %>%
  group_by(embeddings_method) %>%
  filter(embeddings_method != "SDNE") %>%
  mutate(dimension_1 = (dimension_1-min(dimension_1))/(max(dimension_1)-min(dimension_1)),
         dimension_2 = (dimension_2-min(dimension_2))/(max(dimension_2)-min(dimension_2))) %>%
  # mutate(dimension_1 = (dimension_1-mean(dimension_1))/sd(dimension_1),
  #        dimension_2 = (dimension_2-mean(dimension_2))/sd(dimension_2)) %>%
  ggplot(aes(x = dimension_1, y = dimension_2, colour = type)) + 
  geom_point() +
  facet_wrap(~embeddings_method) +
  labs(title = "Seperating Peel's Quintet in 2 dimensions",
       x = "first dimension (tension for SETSe)",
       y = "second dimension (elevation for SETSe)")
#ggsave(file.path(FiguresFolder, "Seperating_Peels_quintet.pdf"))

```

```{r}

#accuracy plot
bind_rows(GEM_embeds, 
          SETSe_embeds, 
          node_perf,
          DGI_embeds %>% filter(.estimate != 0)
          ) %>%
  filter(.metric =="accuracy") %>%
  mutate(type2 = paste0("Type ", type,": ", model_type, " detection") %>% str_replace(., "_", " ")) %>%
  ggplot(aes(x = embeddings_method, y = .estimate, fill = embeddings_method)) + geom_boxplot()+
  facet_wrap(~type2)  +
  guides(fill=FALSE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Comparison of graph embeddings methods for class identification on Peel's Quintet",
       y = "accuracy",
       x = "")
ggsave(file.path(FiguresFolder,  "peels_embedding_linear_sep.pdf"))        

#linearly seperably plot
linear_sep <- bind_rows(GEM_embeds, SETSe_embeds, node_perf, DGI_embeds)%>%
  filter(.metric =="accuracy") %>%
  mutate(linear_sep = .estimate ==1) %>%
  group_by(embeddings_method, type, model_type) %>%
  summarise(fract = sum(linear_sep)/n()) 

linear_sep %>%
  ggplot(aes(x = embeddings_method, y = fract, fill = embeddings_method)) + geom_col() +
  facet_wrap(type~model_type)  +
  guides(fill=FALSE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Comparison of graph embeddings methods for class identification on Peel's Quintet",
       y = "Accuracy of linear seperability",
       x = "Embeddings method")


```

#What is going on with SDNE?
the SDNE values are all 0

```{r}
include<-grepl(embedded_files, pattern = "SDNE")
test <- 1:sum(include) %>%
  map_df(~{
    
    print(.x)
    embedded_path <- embedded_files[include][.x]#embedded_files[50]
    
    #split the file name to get the graph information
    graph_data <- str_split(basename(embedded_path), pattern = "_", simplify = T )
    
    #read the csv in from the folder
    csv_df <- read.csv(embedded_path, header = FALSE) #col_names = FALSE)
     
   csv_df %>%
     summarise_all(~sum(abs(.)))
    
  })
```



```{r}

df <- iris


ggplot(iris, aes( x = Sepal.Width, y = Sepal.Length, colour = Petal.Length)) + geom_point() +
  facet_grid(~Species)

```



#Facebook conversion

This section converts the facebook igraph objects to graphml. They can then be exported to the HPC and the GEM embeddings methods run on them

```{r}

#File paths of all the facebook networks in igraph format
uni_files <- list.files("/home/jonno/setse_1_data/facebook100/facebook100_igraph", full.names = T)

#create new folder
graphml_path <- file.path(PLwd, "facebook100", "facebook100_graphml")
if(!dir.exists(graphml_path)){ dir.create(graphml_path)}

1:length(uni_files) %>% walk(~{
  
  #file path to load
  current_path <- uni_files[.x]
  
  #load file
  g <- read_rds(current_path)
  
  #strip all but major component
  g2 <- remove_small_components(g)
  
  #take only the name and year data
  vertices_df <- as_data_frame(g2, what = "vertices") %>%
    select(name, year)
  edge_df <- as_data_frame(g2)
  
  #new file path
  new_path <- current_path %>% 
    dirname() %>%
    dirname() %>%
    file.path(., "facebook100_graphml"
              , str_replace(basename(current_path), 
                            ".rds", ".graphml") )
  
  #save as graphml
  graph_from_data_frame(edge_df, 
                        directed = FALSE, 
                        vertices = vertices_df) %>%
    write_graph(., file = new_path, format = "graphml" )
  
})

```

##facebook csv

This chunk is used to create the csv that the python script will read from.
The script will use only data from the specific task id


```{r}

expand_grid(model = c("HOPE", 
                      "LapEig", 
                      "LLE", 
                      "SDNE",
                      "node2vec",
                      "DGI"),
            unis = basename(uni_files) %>% str_remove(., ".rds")) %>%
  write_csv(., file.path(PLwd, "facebook_model_uni_python.csv"))

```


#Compare embeddings

##memory

Create a dataframe which contains the memory required for each embedding

```{r}

file_paths <- list.files("/home/jonno/setse_1_data/facebookpython", pattern = "facebookpython.e", full.names = T)

#These are the uni ID's produced by GEM, as node2vec is found using the node2vec library all the entries that correspond to node2vec need to be removed that all values between 401-500 inclusive
GEM_uni_ids<-str_remove(basename(file_paths), ".*\\.") %>% as.integer()

file_paths <- c(file_paths[!(GEM_uni_ids %in% 401:500)],
  list.files("/home/jonno/setse_1_data/facebooknode2vec", pattern = "facebooknode2vec.e", full.names = T),
  list.files("/home/jonno/setse_1_data/facebookstellargraph", pattern = "facebookstellargraph.e", full.names = T)
  )



#this complicated method is because sometimes when I was trying to get it to work
#some examples would be missing. This prevents errors.
python_memory_df <- str_remove(basename(file_paths), ".*\\.") %>% as.integer() %>% map_df(~{

 file_number_to_open <- grep(paste0("\\.", .x, "$"), file_paths)

 file_name <- file_paths[file_number_to_open]

 print_data <- read_lines(file_name)

tibble( Mbytes = print_data[grep("Maximum resident set size", print_data)] %>% str_extract(., "[0-9]+") %>% as.numeric()/1000, 
       file_number = .x
       )

}) 



```


##time

extract the time from the algorithms

```{r}
python_time_taken_df <- str_remove(basename(file_paths), ".*\\.") %>% as.integer() %>% map_df(~{
  

 file_number_to_open <-grep(paste0("\\.", .x, "$"), file_paths)

 file_name <- file_paths[file_number_to_open]

 print_data <- read_lines(file_name)

tibble( time = print_data[grep("Elapsed ", print_data)] %>% str_remove_all("\\\tElapsed \\(wall clock\\) time \\(h:mm:ss or m:ss\\): "), 
       file_number = .x)

})  %>%
  mutate(time_length = str_count(time, pattern = ":"),
         time2 = ifelse(time_length==1, paste0("00:", time), time),
         time2 = hms(time2))


#do the same for SETSe

SETSe_file_paths <- list.files("/home/jonno/setse_1_data/facebook_embeddings/facebookauto", pattern = "facebookauto.e", full.names = T)

SETSe_time_taken <- 1:length(SETSe_file_paths) %>% map_df(~{
  

 file_number_to_open <-grep(paste0("\\.", .x, "$"), SETSe_file_paths)

 file_name <- SETSe_file_paths[file_number_to_open]

 print_data <- read_lines(file_name)

tibble( time = print_data[grep("Elapsed ", print_data)] %>% str_remove_all("\\\tElapsed \\(wall clock\\) time \\(h:mm:ss or m:ss\\): "), 
       data_id = .x)

})  %>%
  mutate(time_length = str_count(time, pattern = ":"),
         time2 = ifelse(time_length==1, paste0("00:", time), time),
         time2 = hms(time2)) %>% 
  select(-data_id) %>%
  bind_cols(., uni_stats %>% arrange(nodes) %>% slice(1:nrow(memory_df_auto))) %>%
  select(time, data_id, time_length, time2, file_name)
  


```


##plot time memory

```{r}

embedding_details <-expand_grid(model = c("HOPE", 
                      "LapEig", 
                      "LLE", 
                      "SDNE",
                      "node2vec",
                      "DGI"
                      ),
            file_name = basename(uni_files) %>% str_remove(., ".rds")) %>%
  mutate(file_number = 1:n()) %>%
  left_join(., python_memory_df) %>%
  left_join(., python_time_taken_df %>% select(file_number, time = time2)) %>%
  left_join(uni_stats %>% select(2:6), by = "file_name") %>%
  bind_rows(., memory_df_auto %>%
              select(nodes, edges, Mbytes, data_id) %>%
              mutate(model = "SETSe") %>%
              left_join(SETSe_time_taken) %>% select(nodes:model, time = time2, file_name)
  ) %>%
  mutate(time2 = as.numeric(time)) %>%
  filter(model %in% c("HOPE", "LapEig","LLE", "SETSe", "node2vec", "DGI"))

#LLE has not been embedded, why?
embedding_details %>%
  group_by(model) %>%
  summarise(count = n())

embedding_details %>%
  filter(model =="SDNE")

#Memory
mem_plot <- embedding_details %>%
 filter(Mbytes <16000) %>%
   # filter(nodes < 9000) %>%
  ggplot(aes(x = nodes/1000, y = Mbytes/1000, colour = model)) + geom_point() +
  labs(title = "Max Megabytes of RAM used during embedding",
       x = "Edges in network (000's)",
       y = "Gigabytes")

#HOPE and LapEig have a quadratic memory usage. LLE is linear but didn't work so is ignored


#Time
time_plot <- embedding_details %>%
  filter(Mbytes <16000) %>%
  #  filter(nodes < 9000) %>%
  ggplot(aes(x = nodes/1000, y = as.numeric(time2)/60, colour = model)) + geom_point() +
  labs(title = "Time used during embedding",
       x = "Total number of nodes in network",
       y = "Minutes")


(time_plot + theme(legend.position="none"))/
    (mem_plot )


test <- time_taken_df %>%
  select(time_per_iter, file_name) %>% 
  mutate(model = "SETSe") %>%
  left_join( embedding_details,.) %>%
  mutate(time2 = time2/60) %>% #convert from seconds to minutes
  filter(Mbytes <16000) %>%
  pivot_longer(., cols = c(Mbytes, time_per_iter, time2)) %>%
  mutate(name = case_when(name=="time2"~"Embedding time (mins)",
                          name =="time_per_iter" ~"Iteration time (secs)",
                          TRUE~ "Memory (Gb)")) %>%
  filter(!is.na(value))

time_plot <-test %>%
  filter(name != "Memory (Gb)") %>%
  ggplot(aes(x = edges/1000, y = value, color = model)) + 
  facet_wrap(~name, scales = "free_y") +
  geom_point() +
 # theme(legend.position = c(0.9, 0.1), legend.justification = c(1, 0)) +
  labs(title = "Space and memory complexity of the embeddings methods",
       x = "number of edges (000's)",
       colour = "Model"
       )


mem_plot <- test %>%
  filter(name == "Memory (Gb)") %>%
  ggplot(aes(x = nodes/1000, y = value/1000, color = model)) + 
  facet_wrap(~name, scales = "free_y") +
  geom_point() +
 # theme(legend.position = c(0.9, 0.1), legend.justification = c(1, 0)) +
  labs(
       x = "number of nodes (000's)",
       colour = "Model",
       y = "value"
       )


cowplot::get_legend(
  # create some space to the left of the legend
  mem_plot)

(time_plot+ theme(legend.position="none") )/ 
  (mem_plot + theme(legend.position="none")| get_legend(
  # create some space to the left of the legend
  mem_plot + theme(legend.box.margin = margin(0, 0, 0, 12) ))
  )
ggsave(file.path(FiguresFolder, "time_complexity.pdf"))
```

```{r}

embedded_files <- list.files("/home/jonno/setse_1_data/facebookpython", pattern = ".csv", full.names = T)

 tibble(embedded_files = basename(embedded_files)) %>%
  separate(col = embedded_files, into = c("model", "file_name"), sep = "_", remove = FALSE) %>%
  mutate(file_name = file_name %>% str_remove(., ".csv")) 

 load_file <- embedded_files[1]
 embeddings_df <- read_csv(load_file, col_names = FALSE)

```


#Assoratativity

Checking how the alternative embedding methods find assorativity

```{r}


  node_details_df <- readRDS(
    file.path("/home/jonno/setse_1_data/facebook_embeddings/processed_embeddings",
                                       "facebook_node_detail.rds" )) %>%
    mutate(abs_elevation = abs(elevation)) %>%
    group_by(file_name) %>%
    summarise_at(., vars(sum_tension:elevation , abs_elevation), mean, na.rm = T) %>%
    left_join(uni_stats, by = "file_name") %>%
  mutate(node_edge = nodes/edges)
```



```{r}
 mean_embeddings_value(folder_path, file_name)
  
```

